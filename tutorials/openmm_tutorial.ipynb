{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb413e3242178b74",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Installing Atomate2 From Source with OpenMM\n",
    "\n",
    "```bash\n",
    "# setting up our conda environment\n",
    ">>> conda create -n atomate2 python=3.11\n",
    ">>> conda activate atomate2\n",
    "\n",
    "# installing atomate2\n",
    ">>> pip install git+https://github.com/orionarcher/atomate2.git\n",
    "\n",
    "# installing classical_md dependencies\n",
    ">>> conda install -c conda-forge --file .github/classical_md_requirements.txt\n",
    "```\n",
    "\n",
    "Alternatively, if you anticipate regularly updating atomate2 from source (which at this point, you should), you can clone the repository and install from source.\n",
    "\n",
    "``` bash\n",
    "# installing atomate2\n",
    ">>> git clone https://github.com/orionarcher/atomate2.git\n",
    ">>> cd atomate2\n",
    ">>> git branch openff\n",
    ">>> git checkout openff\n",
    ">>> git pull origin openff\n",
    ">>> pip install -e .\n",
    "```\n",
    "\n",
    "To test the openmm installation, you can run the following command. If you intend to run on GPU, make sure that the tests are passing for CUDA.\n",
    "\n",
    "```bash\n",
    ">>> python -m openmm.testInstallation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6137bd67d2f0f68b",
   "metadata": {},
   "source": [
    "### Understanding Atomate2 OpenMM \n",
    "\n",
    "Atomate2 is really just a collection of jobflow workflows relevant to materials science. In all the workflows, we pass our system of interest between different jobs to perform the desired simulation. Representing the intermediate state of a classical molecular dynamics simulation, however, is challenging. While the intermediate representation between stages of a periodic DFT simulation can include just the elements, xyz coordinates, and box vectors, classical molecular dynamics systems must also include velocities and forces. The latter is particularly challenging because all MD engines represent forces differently. Rather than implement our own representation, we use the `openff.interchange.Interchange` object, which catalogs the necessary system properties and interfaces with a variety of MD engines. This is the object that we pass between stages of a classical MD simulation and it is the starting point of our workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a0cbf5087b9a6d",
   "metadata": {},
   "source": [
    "### Pouring a Glass of Wine\n",
    "\n",
    "The first job we need to create generates the `Interchange` object. To specify the system of interest, we use give it the SMILES strings, counts, and names (optional) of the molecules we want to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb88df247ef580",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from atomate2.classical_md.core import generate_interchange\n",
    "\n",
    "mol_specs_dicts = [\n",
    "    {\"smile\": \"O\", \"count\": 200, \"name\": \"water\"},\n",
    "    {\"smile\": \"CCO\", \"count\": 10, \"name\": \"ethanol\"},\n",
    "    {\"smile\": \"C1=C(C=C(C(=C1O)O)O)C(=O)O\", \"count\": 1, \"name\": \"gallic_acid\"},\n",
    "]\n",
    "\n",
    "gallic_interchange_job = generate_interchange(mol_specs_dicts, 1.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28650f93c560073f",
   "metadata": {},
   "source": [
    "If you are wondering what arguments are allowed in the dictionaries, check out the `create_mol_spec` function in the `atomate2.classical_md.utils` module. Under the hood, this is being called on each mol_spec dict. Meaning the code below is functionally identical to the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b5a9485bf558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atomate2.classical_md.utils import create_mol_spec\n",
    "\n",
    "mols_specs = [create_mol_spec(**mol_spec_dict) for mol_spec_dict in mol_specs_dicts]\n",
    "\n",
    "generate_interchange(mols_specs, 1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac6d761ef8f6797",
   "metadata": {},
   "source": [
    "In a more complex simulation we might want to scale the ion charges and include custom partial charges. An example with the Gen2 electrolyte is shown below. This yields the `elyte_interchange_job` object, which we can pass to the next stage of the simulation.\n",
    "\n",
    "NOTE: It's actually mandatory to include partial charges for PF6- here, the built in partial charge method fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4673f32a64e51a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T22:13:25.108742Z",
     "start_time": "2024-04-02T22:13:25.102145Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pymatgen.core.structure import Molecule\n",
    "\n",
    "\n",
    "pf6 = Molecule(\n",
    "    [\"P\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\"],\n",
    "    [\n",
    "        [0.0, 0.0, 0.0],\n",
    "        [1.6, 0.0, 0.0],\n",
    "        [-1.6, 0.0, 0.0],\n",
    "        [0.0, 1.6, 0.0],\n",
    "        [0.0, -1.6, 0.0],\n",
    "        [0.0, 0.0, 1.6],\n",
    "        [0.0, 0.0, -1.6]\n",
    "    ]\n",
    ")\n",
    "pf6_charges = np.array([1.34, -0.39, -0.39, -0.39, -0.39, -0.39, -0.39])\n",
    "\n",
    "mol_specs_dicts = [\n",
    "    {\"smile\": \"C1COC(=O)O1\", \"count\": 100, \"name\": \"EC\"},\n",
    "    {\"smile\": \"CCOC(=O)OC\", \"count\": 100, \"name\": \"EMC\"},\n",
    "    {\n",
    "        \"smile\": \"F[P-](F)(F)(F)(F)F\",\n",
    "        \"count\": 50,\n",
    "        \"name\": \"PF6\",\n",
    "        \"partial_charges\": pf6_charges,\n",
    "        \"geometry\": pf6,\n",
    "        \"charge_scaling\": 0.8,\n",
    "        \"charge_method\": \"RESP\",\n",
    "    },\n",
    "    {\"smile\": \"[Li+]\", \"count\": 50, \"name\": \"Li\", \"charge_scaling\": 0.8},\n",
    "]\n",
    "\n",
    "elyte_interchange_job = generate_interchange(mol_specs_dicts, 1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103726640f83c0c",
   "metadata": {},
   "source": [
    "### The basic simulation\n",
    "\n",
    "To run a production simulation, we will create a production flow, link it to our `elyte_interchange_job`, and then run both locally.\n",
    "\n",
    "In jobflow, jobs and flows are created by [Makers](https://materialsproject.github.io/jobflow/tutorials/6-makers.html), which can then be linked into more complex flows. The production maker links together makers for energy minimization, pressure equilibration, annealing, and a nvt simulation. The anneal maker itself creates a flow that links together nvt and tempchange makers (it uses the `from_temps_and_steps` method to save us from creating three more jobs manually). When linked up the `generate_interchange` job this yields a production ready molecular dynamics workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62fbeffc28663bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T22:13:31.417584Z",
     "start_time": "2024-04-02T22:13:28.193031Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-02 15:13:28,211 INFO Started executing jobs locally\n",
      "2024-04-02 15:13:28,217 INFO Starting job - generate_interchange (c1da9796-3b4d-4105-a385-2a0c7a15a5e3)\n",
      "2024-04-02 15:13:31,042 INFO generate_interchange failed with exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/jobflow/managers/local.py\", line 114, in _run_job\n",
      "    response = job.run(store=store)\n",
      "               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/jobflow/core/job.py\", line 583, in run\n",
      "    response = function(*self.function_args, **self.function_kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/projects/development/atomate2/src/atomate2/classical_md/core.py\", line 112, in generate_interchange\n",
      "    mol_specs.append(create_mol_spec(**spec))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/projects/development/atomate2/src/atomate2/classical_md/utils.py\", line 344, in create_mol_spec\n",
      "    openff_mol = create_openff_mol(\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/projects/development/atomate2/src/atomate2/classical_md/utils.py\", line 291, in create_openff_mol\n",
      "    openff_mol, atom_map = add_conformer(openff_mol, geometry)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/projects/development/atomate2/src/atomate2/classical_md/utils.py\", line 182, in add_conformer\n",
      "    is_isomorphic, atom_map = get_atom_map(inferred_mol, openff_mol)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/projects/development/atomate2/src/atomate2/classical_md/utils.py\", line 108, in get_atom_map\n",
      "    isomorphic, atom_map = tk.topology.Molecule.are_isomorphic(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/openff/toolkit/topology/molecule.py\", line 2133, in are_isomorphic\n",
      "    mol2_netx = to_networkx(mol2)\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/openff/toolkit/topology/molecule.py\", line 2116, in to_networkx\n",
      "    data = deepcopy(data)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/copy.py\", line 153, in deepcopy\n",
      "    y = copier(memo)\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/openff/toolkit/topology/molecule.py\", line 1359, in __deepcopy__\n",
      "    return cls(self.to_dict())\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/openff/toolkit/topology/molecule.py\", line 5269, in __init__\n",
      "    super(Molecule, self).__init__(*args, **kwargs)\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/openff/toolkit/topology/molecule.py\", line 1004, in __init__\n",
      "    self._initialize_from_dict(other)\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/openff/toolkit/topology/molecule.py\", line 1251, in _initialize_from_dict\n",
      "    self._add_atom(**atom_dict, invalidate_cache=False)\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/openff/toolkit/topology/molecule.py\", line 2936, in _add_atom\n",
      "    atom = Atom(\n",
      "           ^^^^^\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/openff/toolkit/topology/molecule.py\", line 259, in __init__\n",
      "    self.formal_charge = formal_charge\n",
      "    ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/orioncohen/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/openff/toolkit/topology/molecule.py\", line 359, in formal_charge\n",
      "    raise ValueError\n",
      "ValueError\n",
      "\n",
      "2024-04-02 15:13:31,044 INFO Finished executing jobs locally\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Flow did not finish running successfully",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m      1\u001b[0m production_maker \u001b[38;5;241m=\u001b[39m ProductionMaker(\n\u001b[1;32m      2\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_production\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     energy_maker\u001b[38;5;241m=\u001b[39mEnergyMinimizationMaker(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     nvt_maker\u001b[38;5;241m=\u001b[39mNVTMaker(n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m),\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m production_flow \u001b[38;5;241m=\u001b[39m production_maker\u001b[38;5;241m.\u001b[39mmake(\n\u001b[1;32m     14\u001b[0m     elyte_interchange_job\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39minterchange,\n\u001b[1;32m     15\u001b[0m     prev_task\u001b[38;5;241m=\u001b[39melyte_interchange_job\u001b[38;5;241m.\u001b[39moutput,\n\u001b[1;32m     16\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m \u001b[43mrun_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFlow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43melyte_interchange_job\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduction_flow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m, in \u001b[0;36mrun_job\u001b[0;34m(job)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_job\u001b[39m(job):\n\u001b[0;32m---> 14\u001b[0m     response_dict \u001b[38;5;241m=\u001b[39m \u001b[43mrun_locally\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_success\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(response_dict\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[0;32m~/miniconda3/envs/atomate_emmet/lib/python3.11/site-packages/jobflow/managers/local.py:179\u001b[0m, in \u001b[0;36mrun_locally\u001b[0;34m(flow, log, store, create_folders, root_dir, ensure_success, allow_external_references, raise_immediately)\u001b[0m\n\u001b[1;32m    176\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished executing jobs locally\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_success \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m finished_successfully:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlow did not finish running successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(responses)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Flow did not finish running successfully"
     ]
    }
   ],
   "source": [
    "from atomate2.classical_md.openmm.flows.core import AnnealMaker, ProductionMaker\n",
    "from atomate2.classical_md.openmm.jobs.core import (\n",
    "    EnergyMinimizationMaker,\n",
    "    NPTMaker,\n",
    "    NVTMaker,\n",
    ")\n",
    "from jobflow import Flow, run_locally\n",
    "\n",
    "\n",
    "production_maker = ProductionMaker(\n",
    "    name=\"production_flow\",\n",
    "    energy_maker=EnergyMinimizationMaker(traj_interval=10, state_interval=10),\n",
    "    npt_maker=NPTMaker(n_steps=100),\n",
    "    anneal_maker=AnnealMaker.from_temps_and_steps(n_steps=150),\n",
    "    nvt_maker=NVTMaker(n_steps=100),\n",
    ")\n",
    "\n",
    "production_flow = production_maker.make(\n",
    "    elyte_interchange_job.output.interchange,\n",
    "    prev_task=elyte_interchange_job.output,\n",
    "    output_dir=\"./tutorial_system\",\n",
    ")\n",
    "\n",
    "run_locally(Flow([elyte_interchange_job, production_flow]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd37cfb75071ad3",
   "metadata": {},
   "source": [
    "When the above code is executed, you should expect to see something like this:\n",
    "\n",
    "```\n",
    "/tutorial_system\n",
    "├── state.csv\n",
    "├── state2.csv\n",
    "├── state3.csv\n",
    "├── state4.csv\n",
    "├── state5.csv\n",
    "├── state6.csv\n",
    "├── taskdoc.json\n",
    "├── trajectory.dcd\n",
    "├── trajectory2.dcd\n",
    "├── trajectory3.dcd\n",
    "├── trajectory4.dcd\n",
    "├── trajectory5.dcd\n",
    "├── trajectory6.dcd\n",
    "```\n",
    "\n",
    "We see that each job saved a separate state and trajectory file. There are 6 because the `AnnealMaker` creates 3 sub-jobs and the `EnergyMinimizationMaker` does not report anything. We also see a `taskdoc.json` file, which contains the metadata for the entire workflow. This is needed when we later want to do downstream analysis in `emmet`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912d4d88dce8d11f",
   "metadata": {},
   "source": [
    "### Configuring the Simulation\n",
    "\n",
    "All OpenMM jobs, i.e. anything in `atomate2.classical_md.openmm.jobs`, inherits from the `BaseOpenMMMaker` class. `BaseOpenMMMaker` is highly configurable, you can change the timestep, temperature, reporting frequencies, output types, and a range of other properties. See the docstring for the full list of options.\n",
    "\n",
    "Note that when instantiating the `ProductionMaker` above, we only set the `traj_interval` and `state_interval` once, inside `EnergyMinimizationMaker`. This is a key feature: all makers will inherit attributes from the previous maker if they are not explicitly reset. This allows you to set the timestep once and have it apply to all stages of the simulation. More explicitly, the value inheritance is as follows: 1) any explictly set value, 2) the value from the previous maker, 3) the default value, shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7d88391851bce0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T14:38:53.623251Z",
     "start_time": "2024-06-01T14:38:53.618119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': 0.001,\n",
       " 'temperature': 298,\n",
       " 'friction_coefficient': 1,\n",
       " 'platform_name': 'CPU',\n",
       " 'platform_properties': {},\n",
       " 'state_interval': 1000,\n",
       " 'state_file_name': 'state',\n",
       " 'traj_interval': 10000,\n",
       " 'wrap_traj': False,\n",
       " 'report_velocities': False,\n",
       " 'traj_file_name': 'trajectory',\n",
       " 'traj_file_type': 'dcd',\n",
       " 'embed_traj': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from atomate2.classical_md.openmm.jobs.base import OPENMM_MAKER_DEFAULTS\n",
    "OPENMM_MAKER_DEFAULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf76faf2e5faf9",
   "metadata": {},
   "source": [
    "Perhaps we want to record a trajectory with velocities but only for the final NVT run.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1192be40dc8b7af8",
   "metadata": {},
   "source": [
    "### Running with Databases\n",
    "\n",
    "Before trying this, you should have a basic understanding of JobFlow and [Stores](https://materialsproject.github.io/jobflow/stores.html).\n",
    "\n",
    "To log OpenMM results to a database, you'll need to set up both a MongoStore, for taskdocs, and blob storage, for trajectories. Here, I'll show you the correct jobflow.yaml file to use the MongoDB storage and MinIO S3 storage provided by NERSC. To get this up, you'll need to contact NERSC to get accounts on their MongoDB and MinIO services. Then you can follow the instructions in the [Stores](https://materialsproject.github.io/jobflow/stores.html) tutorial to link jobflow to your databases. Your `jobflow.yaml` should look like this:\n",
    "\n",
    "```yaml\n",
    "JOB_STORE:\n",
    "  docs_store:\n",
    "    type: MongoStore\n",
    "    database: DATABASE\n",
    "    collection_name: atomate2_docs # suggested\n",
    "    host: mongodb05.nersc.gov\n",
    "    port: 27017\n",
    "    username: USERNAME\n",
    "    password: PASSWORD\n",
    "\n",
    "  additional_stores:\n",
    "      data:\n",
    "          type: S3Store\n",
    "          index:\n",
    "              type: MongoStore\n",
    "              database: DATABASE\n",
    "              collection_name: atomate2_blobs_index # suggested\n",
    "              host: mongodb05.nersc.gov\n",
    "              port: 27017\n",
    "              username: USERNAME\n",
    "              password: PASSWORD\n",
    "              key: blob_uuid\n",
    "          bucket: oac\n",
    "          s3_profile: oac\n",
    "          s3_resource_kwargs:\n",
    "              verify: false\n",
    "          endpoint_url: https://next-gen-minio.materialsproject.org/\n",
    "          key: blob_uuid\n",
    "```\n",
    "\n",
    "NOTE: This can work with any MongoDB and S3 storage, not just NERSC's.\n",
    "\n",
    "Rather than use `jobflow.yaml`, you could also create the stores in Python and pass the stores to the `run_locally` function. This is shown below for completeness but the prior method is usually recommended.\n",
    "\n",
    "\n",
    "```python\n",
    "from jobflow import run_locally, JobStore\n",
    "from maggma.stores import MongoStore, S3Store, MemoryStore\n",
    "\n",
    "md_doc_store = MongoStore(\n",
    "    username=\"USERNAME\",\n",
    "    password=\"PASSWORD\",\n",
    "    database=\"DATABASE\",\n",
    "    collection_name=\"atomate2_docs\", # suggested\n",
    "    host=\"mongodb05.nersc.gov\",\n",
    "    port=27017,\n",
    ")\n",
    "\n",
    "md_blob_index = MongoStore(\n",
    "    username=\"USERNAME\",\n",
    "    password=\"PASSWORD\",\n",
    "    database=\"DATABASE\",\n",
    "    collection_name=\"atomate2_blobs_index\", # suggested\n",
    "    host=\"mongodb05.nersc.gov\",\n",
    "    port=27017,\n",
    "    key=\"blob_uuid\",\n",
    ")\n",
    "\n",
    "md_blob_store = S3Store(\n",
    "    index=md_blob_index,\n",
    "    bucket=\"BUCKET\",\n",
    "    s3_profile=\"PROFILE\",\n",
    "    endpoint_url=\"https://next-gen-minio.materialsproject.org\",\n",
    "    key=\"blob_uuid\",\n",
    ")\n",
    "\n",
    "wf = [] # set up whatever workflow you'd like to run\n",
    "\n",
    "# run the flow with our custom store\n",
    "run_locally(\n",
    "    wf,\n",
    "    store=JobStore(md_doc_store, additional_stores={\"data\": md_blob_store}),\n",
    "    ensure_success=True,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f910256d24cf77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fad336e4227d4be8",
   "metadata": {},
   "source": [
    "### Running on GPU(s)\n",
    "\n",
    "Running on a GPU is nearly as simple as running on a CPU. The only difference is that you need to specify the `platform_properties` argument in the `EnergyMinimizationMaker` with the `DeviceIndex` of the GPU you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8d79a1826fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_maker = ProductionMaker(\n",
    "    name=\"test_production\",\n",
    "    energy_maker=EnergyMinimizationMaker(\n",
    "        platform_name=\"CUDA\",\n",
    "        platform_properties={\"DeviceIndex\": \"0\"},\n",
    "    ),\n",
    "    npt_maker=NPTMaker(n_steps=100),\n",
    "    anneal_maker=AnnealMaker.from_temps_and_steps(n_steps=150),\n",
    "    nvt_maker=NVTMaker(n_steps=1000),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec4a2dedc26d6e",
   "metadata": {},
   "source": [
    "Some systems (notably perlmutter) have multiple GPUs available on a single node. To fully leverage the compute, you'll need to distribute 4 simulations across the 4 GPUs. A simple way to do this is with MPI.\n",
    "\n",
    "First you'll need to install mpi4py.\n",
    "\n",
    "```bash\n",
    ">>> conda install mpi4py\n",
    "```\n",
    "\n",
    "Then you can modify and run the following script to distribute the work across the GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25935190d65ce690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other imports\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "list_of_mol_spec_lists = []\n",
    "# logic to add four mol_spec_lists to list_of_mol_spec_lists\n",
    "\n",
    "\n",
    "flows = []\n",
    "for i in range(4):\n",
    "    device_index = i\n",
    "    mol_specs = list_of_mol_spec_lists[i]\n",
    "    \n",
    "    setup = generate_interchange(mol_specs, 1.0)\n",
    "    \n",
    "    production_maker = ProductionMaker(\n",
    "        name=\"test_production\",\n",
    "        energy_maker=EnergyMinimizationMaker(\n",
    "            platform_name=\"CUDA\",\n",
    "            platform_properties={\"DeviceIndex\": str(device_index)},\n",
    "        ),\n",
    "        npt_maker=NPTMaker(n_steps=200000),\n",
    "        anneal_maker=AnnealMaker.from_temps_and_steps(n_steps=1500000),\n",
    "        nvt_maker=NVTMaker(n_steps=5000000, embed_traj=True),\n",
    "    )\n",
    "\n",
    "    production_flow = production_maker.make(\n",
    "        setup.output.interchange,\n",
    "        prev_task=setup.output,\n",
    "        output_dir=f\"/pscratch/sd/o/oac/openmm_runs/{i}\",\n",
    "    )\n",
    "    flows.append(Flow([setup, production_flow]))\n",
    "\n",
    "# this script will run four times, each with a different rank, thus distributing the work across the four GPUs.\n",
    "run_locally(flows[rank], ensure_success=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomate_emmet",
   "language": "python",
   "name": "atomate_emmet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
